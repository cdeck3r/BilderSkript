<!DOCTYPE html>
<html>
<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
	<meta name="description" content="
		
		Engineering Documentation
		"> 
    
	<meta name="author" content=" cdeck3r ">  
    <base href="https://cdeck3r.com/BilderSkript/">
    <title>BilderSkript</title>

    
    <link href="css/bootstrap.min.css" rel="stylesheet">

    
    <link href="css/landing-page.css" rel="stylesheet">

    
    <link href="https://fonts.googleapis.com/css?family=Lato:300,400,700,300italic,400italic,700italic" rel="stylesheet" type="text/css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">

    
    <link href="css/bootstrap-social.css" rel="stylesheet">

    
    
    

    <style>
    .navbar {
    border-color: #e7e7e7;
}

.content-section-a,
footer,
.navbar {
  background-color: #f8f8f8;
  color: #333;
}

.navbar a:link,
.navbar-default .navbar-nav>li>a {
  color: #777;
}

.navbar a:hover,
.navbar-default .navbar-nav>li>a:hover {
  color: rgb(51, 51, 51);
}

.content-section-b {
  background-color: white;
  color: #333;
}

body {
  color: rgb(51, 51, 51);
}

.header-container h1,
.header-container h2,
.header-container h3,
.header-container h4 {
  color: rgb(51, 51, 51);
}
 
  </style>

</head>
<body>

<section id="intro">
	
	<div class="intro-header">

		<div class="container">
			<div class="row">
				<div class="col-lg-12">
				
					<div class="intro-message">
						<h1>BilderSkript</h1>
						<h3>Engineering Documentation</h3>
						<hr class="intro-divider">

						<ul class="list-inline intro-social-buttons">
						


  <li><a href="//github.com/cdeck3r/BilderSkript" class="btn btn-default btn-lg" title="GitHub">
  <i class="fa fa-github"></i>
  </a></li>


























  <li><a href="//linkedin.com/in/cdeck3r" title="LinkedIn" class="btn btn-default btn-lg">
  <i class="fa fa-linkedin"></i>
  </a></li>



















  <li><a href="//youtube.com/channel/UCZ5wNVV_E6AA3L3C-mvqwSA" title="YouTube" class="btn btn-default btn-lg">
  <i class="fa fa-youtube"></i>
  </a></li>













  <li><a href="//instagram.com/cdeck3r" title="Instagram" class="btn btn-default btn-lg">
  <i class="fa fa-instagram"></i>
  </a></li>





  <li><a href="//twitter.com/cdeck3r" title="Twitter" class="btn btn-default btn-lg">
  <i class="fa fa-twitter"></i>
  </a></li>



















  <li><a href="mailto:info@cdeck3r.com" title="Email" class="btn btn-default btn-lg">
  <i class="fa fa-envelope"></i>
  </a></li>


						</ul>
					</div>
				</div>
			</div>
		</div>
		
	</div>
	
</section>

<section id="main">



	 
    <div class="content-section-a">
    
   
        <div class="container">

            <div class="row">
                <div>
                    
                    <h2 class="section-heading">About</h2>
                    

<h2 id="bilderskript">BilderSkript</h2>

<p>BilderSkript is a compound created from the following words.</p>

<blockquote>
<p>Bilder [ˈbɪldɐ], (German), images</p>

<p>Skript [skʁɪpt], (German), a written document or notes</p>
</blockquote>

<p>BilderSkript automatically summarizes a lecture as a sequence of interesting images scenes.</p>

<p>Technically, it trains a deep neural net on objection recognition and extracts interesting scenes from a large sequence of still image recordings. Theses scenes compile to the BilderSkript</p>

                </div>
            </div>

        </div>
        

    </div>

	
    <div class="content-section-b">
    
   
        <div class="container">

            <div class="row">
                <div>
                    
                    <h2 class="section-heading">Project Definition</h2>
                    

<h3 id="motivation-and-goal">Motivation and Goal</h3>

<p>A lecturer usually provides a lot of supplemental course material such as a written script, slides, reading material, exercises.</p>

<p>However, students visiting the course&rsquo;s lecture experience an additional channel, which helps them to sort and weight the supplemental material. The way how a lecturer presents the content will let attendees realize the weight and importance of certain parts of the content. Hence, it supports the creation of a red thread throughout entire supplemental material.</p>

<p>In contrast to full lecture recording, the BilderSkript approach condenses the recording to find those parts within a lecture which contribute to the understanding of the supplemental material.</p>

<p>Primarily, BilderSkript aims at course attendees, however, it could also be valuable for remote attentees.</p>

<p>BilderSkript has the following goals</p>

<ul>
<li>re-create partially the course experience</li>
<li>support attenting students to follow-up on the content</li>
<li>support students who have not attended all lessions to catch-up on the course</li>
<li>improve the efficiency when working with the supplemental course material</li>
</ul>

<h3 id="objectives">Objectives</h3>

<p>There are a couple of activities to perform</p>

<ul>
<li>record lectures as a sequence of wide angle still images</li>
<li>train a computer to identify objects within still images</li>
<li>define a metric of interestingness from the sequence of recognized objects</li>
<li>extract interesting images and compile a lecture notebook from which ultimately creates the BilderSkript</li>
</ul>

<h3 id="research-questions">Research Questions</h3>

<p>BilderSkript relies on widely available open-source ML software. However, there are a couple of interesting research questions on the way.</p>

<ul>
<li><strong>How to automate image preprocessing?</strong> - Image recording activity does not happen in a controlled environment, i.e. lecture rooms change, the light varies, the camera positions are not fixed (resulting in varying field of views), varying colors of background, cloths etc.</li>
<li><strong>Can we successfully transfer other object identfication models to lecture recordings?</strong> Object identfication utilizes labeled data from one or few lectures for training. Since labeling is laborious, we are interested to transfer trained models from other areas and apply for object identfication in our lecture recordings.</li>
</ul>

                </div>
            </div>

        </div>
        

    </div>

	 
    <div class="content-section-a">
    
   
        <div class="container">

            <div class="row">
                <div>
                    
                    <h2 class="section-heading">Introductionary Example</h2>
                    <style>
img {
  max-width: 100%;
  height: auto;
}
</style>

<p>BilderSkript takes a series of still images as input and compiles visual lecture notes as output.
Below we illustrate a step-by-step walkthrough how the software processes the data.</p>

<p><strong>Image recording:</strong> A 360 camera records the entire room. However, the lens towards the audience is covered to maintain privacy. The images have the typical distorted appearance due to the camera&rsquo;s fisheye lenses. Nevertheless, it creates an approx. 200 degrees, wide-angle recording.</p>

<p><img src="img/fisheye.jpg" alt="fisheye raw image" width="50%" /></p>

<p><strong>Image preparation:</strong> The BilderSkript projects fisheye images as equirectangular images to correct for the distortion.</p>

<p><img src="img/fisheye_flat.png" alt="fisheye equirectangular projections" width="50%" /></p>

<p>Finally, the perspective control corrects the deformation of vertical and horizontal lines when the camera records the projection wall or blackboard from an inclinded position.</p>

<p><img src="img/fisheye_flat_pc.png" alt="perspective control" width="50%" /></p>

<p><strong>Object identfication:</strong> In this step BilderSkript identifies typical objects, such as blackboard, lecturer, video projection, within each image.</p>

<p><em>tbd. include image</em></p>

<p><strong>Classification:</strong> In particular, if there is a blackboard, it is interesting to know whether the board is empty or not. The classifiers utilizes the identified blackboard from the previous step and assigns class labels, which correspond to the blackboard&rsquo;s state. This step may filter images before it inputs them to the classifier.</p>

<table class='table table-striped table-hover'>
<thead>
<tr>
<th>Label</th>
<th>Original Image</th>
<th>Filtered Image</th>
</tr>
</thead>

<tbody>
<tr>
<td>empty</td>
<td><img src="img/blackboard_empty.png" alt="empty blackboard" width="50%" /></td>
<td><img src="img/blackboard_empty_filter.png" alt="filtered empty blackboard" /></td>
</tr>

<tr>
<td>full</td>
<td><img src="img/blackboard_full.png" alt="full blackboard" width="50%" /></td>
<td><img src="img/blackboard_full_filter.png" alt="filtered full blackboard" /></td>
</tr>
</tbody>
</table>

<p><strong>Sequencing:</strong> Utilizing the object id, it transforms the set of images into a sequence of object compositions. A step consists of all identified objects in a single image. Please note, each step links back to the original image.</p>

<p><em>tbd. include image</em></p>

<p><strong>Interesting sequences:</strong> This steps only operates on the sequence of identified objects. Based on a definition on interestingness, it quantifies the previously created sequences on this metric. The idea is that interestingness emerges from changes in the composition of identified objects.</p>

<p><em>tbd. include image</em></p>

<p><strong>Compilation:</strong> By the degree of interestingness BilderSkript applies a threshold to extract the best ones. Once it has found an interesting sequence, it links each step within this sequence back to its image where it originates from. Finally, it compiles the scene from these images.</p>

<p><em>tbd. include image</em></p>

                </div>
            </div>

        </div>
        

    </div>

	
    <div class="content-section-b">
    
   
        <div class="container">

            <div class="row">
                <div>
                    
                    <h2 class="section-heading">System Design</h2>
                    <style>
img {
  max-width: 100%;
  height: auto;
}
</style>

<p>This use case diagram depicts BilderSkript&rsquo;s main services. Note, the shown use cases do not imply an execution order.</p>

<p><img src="uml/systemdesign.png" alt="system's dataflow" /></p>

<p>The engineer performs the system setup, configures and trains the system for the user to be beneficial.</p>

                </div>
            </div>

        </div>
        

    </div>

	 
    <div class="content-section-a">
    
   
        <div class="container">

            <div class="row">
                <div>
                    
                    <h2 class="section-heading">Docker Container Toolchain</h2>
                    

<style>
img {
  max-width: 100%;
  height: auto;
}
</style>

<h3 id="docker-images-and-volumes">Docker Images and Volumes</h3>

<p>Docker images contain the various software pipelines from the tool chain. The  responsibilities within the overall system design motivate the system boundaries induced by the distribution of pipelines across docker images. The following table list the docker images and their respective pipeline functionalities.</p>

<table class='table table-striped table-hover'>
<thead>
<tr>
<th>Image</th>
<th>Pipeline</th>
<th>Notes</th>
</tr>
</thead>

<tbody>
<tr>
<td>vscode</td>
<td>n/a</td>
<td>IDE VS code</td>
</tr>

<tr>
<td>builder</td>
<td>Build</td>
<td>makefile, doc, versioning via git and dvc, mlflow exp.</td>
</tr>

<tr>
<td>hugin</td>
<td>Data prep</td>
<td>image data preparation using <a href="http://hugin.sourceforge.net/">hugin</a></td>
</tr>

<tr>
<td>hugin-vnc</td>
<td>n/a</td>
<td>like hugin, but provides VNC server for GUI interaction</td>
</tr>

<tr>
<td>mrcnn</td>
<td>ML training</td>
<td>object detection</td>
</tr>

<tr>
<td>ludwig</td>
<td>ML training</td>
<td>classification</td>
</tr>

<tr>
<td>cicd</td>
<td>Deployment pipeline</td>
<td>not yet implemented</td>
</tr>
</tbody>
</table>

<p>When started as docker containers, they run scripts and communicate with each other utilizing shared volumes on the filesystem. The image below illustrates the docker toolchain.</p>

<p><img src="uml/docker_toolchain.png" alt="docker toolchain" /></p>

<p>The most important volumes are:</p>

<ul>
<li>${APP_ROOT}/ipc : used to store sockets for IPCs between containers</li>
<li>${APP_ROOT}/pipelines : contains all BilderSkript pipelines</li>
<li>${APP_ROOT}/images : data directory</li>
<li>${APP_ROOT}/src : stores source codes</li>
<li>${APP_ROOT}/scripts : scripts</li>
<li>${APP_ROOT}/ludwig : stores experiments, models and prediction</li>
<li>${APP_ROOT}/vscode : maintains the state of VS code</li>
<li>${APP_ROOT}/docs :  github&rsquo;s webserver serves the docu blog from this directory</li>
<li>${APP_ROOT}/docs_site : the docu blog&rsquo;s source</li>
</ul>

<p>By default <code>${APP_ROOT}</code> is set to <code>/bilderskript</code>. For instance, one accesses the pipeline scripts under <code>/bilderskript/pipelines</code>.</p>

<h3 id="build-and-startup">Build and Startup</h3>

<p><a href="https://docs.docker.com/compose/">Docker Compose</a> creates all images, containers and volumes. The configuration is defined in the <a href="https://github.com/cdeck3r/BilderSkript/blob/master/docker-compose.yml">docker-compose.yml</a> file</p>

<p>Building all images using the following command</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">docker-compose build</code></pre></div>
<p>Start a container from <code>builder</code> image  and get a <code>bash</code> shell. The default container name is <code>bilderskript_builder_1</code></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">docker-compose up -d builder
docker exec -it bilderskript_builder_1 /bin/bash</code></pre></div>
                </div>
            </div>

        </div>
        

    </div>

	
    <div class="content-section-b">
    
   
        <div class="container">

            <div class="row">
                <div>
                    
                    <h2 class="section-heading">Pipelines</h2>
                    

<style>
img {
  max-width: 100%;
  height: auto;
}
</style>

<p>Pipelines are the fundamental building blocks of the BilderSkript system.</p>

<h3 id="pipeline-definitions">Pipeline Definitions</h3>

<p>The term pipeline is heavily used in machine learning (ML). It generally refers to a sequence of steps to run in order to perform transformations. There are various kinds of pipelines, e.g. data pipelines, machine learning pipelines, deployment pipelines and others. Depending on the pipeline type, it takes a a certain ressource type as input and produces output ressources by the application of the pipeline&rsquo;s transformation steps. For instance, a data pipeline takes data files as an input and prepares them to be fed into a machine learning algorithm of the ML pipeline.</p>

<p>BilderSkript stores pipelines in the <code>pipelines</code> volume usually accessed under <code>/bilderscript/pipelines</code>. They are encoded as snakemake makefiles for version control.</p>

<h3 id="snakemake">Snakemake</h3>

<p><a href="https://snakemake.readthedocs.io/en/stable/">Snakemake</a> is a workflow management system to implement data analysis pipelines.</p>

<p>Snakemake compares the input and output ressources. These ressources are files. If the modification date of any of the input files is newer than the output file, snakemake runs the shell command. This behavior is encoded as rules, which transform input files into output files. All rules of a pipeline are defined in a snakefile. We list some important snakemake commands.</p>

<p>Run the snakemake pipeline</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">snakemake &lt;pipeline name&gt;</code></pre></div>
<p>Generate a report</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">snakemake &lt;pipeline name&gt; --report &lt;snakefile.html&gt;</code></pre></div>
<p>Generate a summary table displaying the current state of input and output files.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">snakemake &lt;pipeline name&gt; --summary</code></pre></div>
<p>Before the snakefile is run, snakemake generates a <a href="https://en.wikipedia.org/wiki/Directed_acyclic_graph">DAG</a> which shows the dependencies. This command visualizes the DAG.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">snakemake &lt;pipeline name&gt; --dag | dot -Tpng &gt; &lt;pipeline name&gt;.png</code></pre></div>
                </div>
            </div>

        </div>
        

    </div>

	 
    <div class="content-section-a">
    
   
        <div class="container">

            <div class="row">
                <div>
                    
                    <h2 class="section-heading">BilderSkript Pipelines</h2>
                    <style>
img {
  max-width: 100%;
  height: auto;
}
</style>

<p>The BilderSkript pipelines follow the guidelines of <a href="https://github.com/snakemake-workflows/docs">The Snakemake-Workflows project</a>. There is a central <code>Snakemake</code> file which includes the configuration and the concrete workflows for the data and ML pipelines.</p>

<p>The workflow&rsquo;s design separates the pipeline specific parameters from the dataset specific ones. A separate file stores each parameter set</p>

<ul>
<li><code>config.yaml</code> contains the pipeline specific parameters. This file exists only once and contains the parameters for all pipelines.</li>
<li><code>dataset.csv</code> stores the parameters relevant for the dataset a pipeline processes. There may be several of these files, one for each class of data for a pipeline. There is no fixed schema. The file&rsquo;s name depends on the content and the pipeline, which sources the file. A pipeline which processes various ML models may utilize a <code>models.csv</code> file to store the set of available models and additional parameters for each model.</li>
</ul>

<p>The approach increases the flexibility to apply the pipelines to various datasets. The figure below depicts this separation</p>

<p><img src="uml/workflow_design.png" alt="workflow design for all pipelines" /></p>

<p>The pipelines are named after their snakefile. All pipelines files stay in the <code>/bilderskript/pipelines</code> directory relative to the BilderSkript&rsquo;s project dir.</p>

<ul>
<li><p><strong><a href="https://github.com/cdeck3r/BilderSkript/blob/master/pipelines/doc.snakefile">doc.snakefile</a>:</strong> describes the pipeline for documentation generations. You may view the pipeline&rsquo;s <a href="https://github.com/cdeck3r/BilderSkript/blob/master/pipelines/doc.snakefile.html">report</a>.</p></li>

<li><p><strong><a href="https://github.com/cdeck3r/BilderSkript/blob/master/pipelines/data_prep.snakefile">data_prep.snakefile</a>:</strong> prepares the image files for the ML pipeline. It&rsquo;s a complex pipeline because it utilizes interprocess communication (IPC) with the <code>hugin</code> container. You may view the pipeline&rsquo;s <a href="https://github.com/cdeck3r/BilderSkript/blob/master/pipelines/data_prep.snakefile.html">report</a>.
<code>data_prep.snakefile</code> requires parameters in <code>config.yaml</code>:</p>

<ul>
<li>datasets_idx: line in <code>datasets.csv</code> defining the data to process</li>
<li>out_dir: the directory where prep&rsquo;ed images as a result of the pipeline execution are stored</li>
</ul>

<p>The pipeline&rsquo;s default behavior is started by the <a href="https://github.com/cdeck3r/BilderSkript/blob/master/pipelines/data_prep.sh"><code>data_prep.sh</code></a> script. The pipeline&rsquo;s rule DAG is shown in <a href="https://github.com/cdeck3r/BilderSkript/blob/master/pipelines/data_prep.snakefile.png"><code>data_prep.snakefile.png</code></a></p></li>

<li><p><strong>ludwig.snakefile:</strong> detects the blackboard&rsquo;s state of writing, i.e. whether the writing on the blackboard fills out the blackboard completely, partially, or alternatively, the blackboard is empty.</p>

<p>The pipeline&rsquo;s default behavior is started by the [<code>ludwig.sh</code>]</p></li>
</ul>

<p>Run the following script to create reports for all BilderSkript pipelines</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">snakemake_report.sh</code></pre></div>
                </div>
            </div>

        </div>
        

    </div>

	
    <div class="content-section-b">
    
   
        <div class="container">

            <div class="row">
                <div>
                    
                    <h2 class="section-heading">[data_prep.snakefile] Pipeline</h2>
                    

<style>
img {
  max-width: 100%;
  height: auto;
}
</style>

<p>The data preparation pipeline, <code>data_prep.snakefile</code>, comprises of two phases</p>

<ol>
<li>Configure the pipeline&rsquo;s parameters

<ul>
<li><code>config.yaml</code> defines pipeline specific parameters</li>
<li><code>datasets.csv</code> defines the data input and data-specific processing parameters</li>
</ul></li>
<li>Run the pipeline on the images from the lecture recording

<br /></li>
</ol>

<h3 id="1-configuration">1. Configuration</h3>

<p>The following activity diagram describes the steps to configure the data preparation pipeline. Configuration is stored in <code>config.yaml</code> and <code>dataset.csv</code>.</p>

<p><strong>Precondition:</strong></p>

<ul>
<li><code>builder</code> and <code>hugin-vnc</code> container up and running</li>
<li>at least one image from lecture recording available</li>
</ul>

<p><strong>Postcondition:</strong></p>

<ul>
<li>images directories set</li>
<li><code>.pto</code> files created</li>
<li>(optionally) crop specification defined</li>
</ul>

<p>The parameter values from above need to be stored in the <code>config.yaml</code> and <code>dataset.csv</code> file. The activity diagram indicates to which file each parameter belongs to.</p>

<p><strong>Commands</strong></p>

<p>Spin up the <code>hugin-vnc</code> container.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">docker-compose up -d hugin-vnc</code></pre></div>
<p>Afterwards, use a vnc client to get Hugin&rsquo;s display and create the <code>.pto</code> files. Modify the pipeline&rsquo;s <code>dataset.csv</code> and <code>config.yaml</code> to tell the scripts where to look for the files. The activity diagram below displays the steps to create the files.</p>

<p><img src="uml/data_prep_config.png" alt="data prep configuration" width="65%" /></p>

<h3 id="2-run-the-pipeline">2. Run the Pipeline</h3>

<p>Finally, the engineer starts the data prep pipeline and the pipeline processes the input images from the <em>img_dir</em> and places it in the <em>out_dir</em>.</p>

<p><strong>Precondition:</strong></p>

<ul>
<li><code>builder</code> and <code>hugin</code> container up and running</li>
<li><code>.pto</code> files created</li>
<li><em>img_dir</em> and <em>out_dir</em> image directories set</li>
</ul>

<p>Parameter values from above are sourced from the the <code>dataset.csv</code> file.</p>

<p><strong>Postcondition:</strong></p>

<ul>
<li>images processed placed in <em>out_dir</em></li>
</ul>

<p><strong>Pipeline Start</strong></p>

<p>The following commands start the pipeline. The activity diagram belows depicts the details of the pipeline run.</p>

<p>Spin up the <code>builder</code> and <code>hugin</code> container and get an interactive shell to the <code>builder</code> container.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">docker-compose up -d builder hugin
docker exec -it bilderskript_builder_1 /bin/bash</code></pre></div>
<p>Within the <code>builder</code> container run</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">cd BilderSkript/pipelines
./data_prep.sh</code></pre></div>
<p><img src="uml/data_prep_run.png" alt="data prep run" width="75%" /></p>

                </div>
            </div>

        </div>
        

    </div>

	 
    <div class="content-section-a">
    
   
        <div class="container">

            <div class="row">
                <div>
                    
                    <h2 class="section-heading">[ludwig.snakefile] Pipeline for Blackboard Classification</h2>
                    <style>
img {
  max-width: 100%;
  height: auto;
}
</style>

<p>The <code>ludwig.snakefile</code> pipeline takes blackboard images as input and assigns labels like full, partial, empty. It indicates the whether the writing on the blackboard fills out the blackboard completely, partially, or alternatively, the blackboard is empty.</p>

                </div>
            </div>

        </div>
        

    </div>

	
    <div class="content-section-b">
    
   
        <div class="container">

            <div class="row">
                <div>
                    
                    <h2 class="section-heading">[doc.snakefile] Pipeline Generating the Blog</h2>
                    <style>
img {
  max-width: 100%;
  height: auto;
}
</style>

<p>The pipeline <code>doc.snakefile</code> generates</p>

<ol>
<li>UML diagrams using <a href="https://plantuml.com/en/">plantuml</a></li>
<li>the project&rsquo;s website using <a href="https://gohugo.io/">hugo</a></li>
</ol>

<p>Run the pipeline from within the <code>builder</code> container in <code>/bilderskript/pipelines</code></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">snakemake doc</code></pre></div>
                </div>
            </div>

        </div>
        

    </div>

	 
    <div class="content-section-a">
    
   
        <div class="container">

            <div class="row">
                <div>
                    
                    <h2 class="section-heading">Train the Blackboard Image Classifier</h2>
                    

<style>
img {
  max-width: 100%;
  height: auto;
}
</style>

<p>The image classifier detects the blackboard&rsquo;s state of writing. It is an interesting BilderSkript context to know whether the writing on the blackboard fills out the blackboard completely, partially, or alternatively, the blackboard is empty.</p>

<h3 id="experiment">Experiment</h3>

<p>We learn a model, a classifier, which maps images to class labels, e.g. full, partial, empty.</p>

<ul>
<li>utilizes the Ludwig docker container</li>
<li>runs from command line;</li>
<li>script tests whether the container already runs and if appropriate spins it up</li>
<li>utilizes <a href="comet.ml">comet.ml</a> to store experiment results</li>
<li>manually shutdown the container</li>
</ul>

<p>For utilizing <a href="comet.ml">comet.ml</a> you need to provide a <code>.comet.env</code> file in the project&rsquo;s directory. The file conatins the API key and the comet&rsquo;s project name.</p>

<p><strong>Walkthrough</strong></p>

<p>Start an experiment from <code>scripts/ludwig</code>.</p>

<p><strong>STEP 1:</strong> Prepare the input dataset</p>

<p>Precondition:</p>

<ul>
<li>`.png&rsquo; images as input for training the model</li>
<li>within the <code>&lt;training image path&gt;</code> directory the images are organized in subdirs, where subdir names are the class labels</li>
<li>experiment name, e.g. <em>stats_lecture</em></li>
</ul>

<p>Command:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">./ludwig_experiment.sh datacsv &lt;experiment name&gt; &lt;training image path&gt;</code></pre></div>
<p>Postcondition:</p>

<ul>
<li>directory created: <code>ludwig/experiements/&lt;experiment name&gt;</code></li>
<li>directory contains <code>&lt;experiment name&gt;.csv</code>, which links images to class labels</li>
</ul>

<p><strong>STEP 2:</strong> Learn the model</p>

<p>Precondition: see above</p>

<p>Command:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">./ludwig_experiment.sh experiment &lt;experiment name&gt; &lt;training image path&gt;</code></pre></div>
<p>Postcondition:</p>

<ul>
<li>Results available in <code>ludwig/experiements/&lt;experiment name&gt;/results</code></li>
<li><a href="comet.ml">comet.ml</a> website contains experiment&rsquo;s results</li>
</ul>

<p><strong>STEP 3:</strong> Visualize and Shutdown</p>

<p>Precondition: the experiment name from above</p>

<p>Command:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">./ludwig_experiment.sh visualize &lt;experiment name&gt; 
./ludwig_experiment.sh shutdown &lt;experiment name&gt; </code></pre></div>
<p>Postcondition:</p>

<ul>
<li><a href="comet.ml">comet.ml</a> website contains for addtional images from the experiment run</li>
<li>the Ludwig container is removed.</li>
</ul>

<h3 id="multi-experiments">Multi Experiments</h3>

<p>Multi experiements are repeated experiements which varying parameters. Particularly, we vary the parameters for the image pre-processing.</p>

<p>Start a multi experiment from <code>scripts/ludwig</code>. All directories created during an regular experiment are prefixed by <code>exp&lt;num&gt;_</code> indicating the run number within the multi experiment.</p>

<p>Precondition:</p>

<ul>
<li>see initial preconditions of a single experiment</li>
<li>edit <code>ludwig_multi_experiments.sh</code> for

<ul>
<li>training image path</li>
<li>parameters to to loop through</li>
</ul></li>
</ul>

<p>Command:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">./ludwig_multi_experiments.sh &lt;experiment root name&gt;</code></pre></div>
<p>Postcondition:</p>

<ul>
<li>directories with results created: <code>ludwig/experiements/exp&lt;num&gt;_&lt;experiment root name&gt;</code></li>
<li><a href="comet.ml">comet.ml</a> website contains all experiments&rsquo; results</li>
</ul>

<h3 id="training-process">Training Process</h3>

<p>The following activity diagram illustrates the overall sequence of actions for running one or more experiments. The swimlane <code>Experiments</code> depicts all artifacts which relate to an experiment. When an experiment is repeated with different parameters the filtered images, the datacsv file and the resulting model are created under the new experiment name.</p>

<p><img src="uml/ludwig_multi_exp" alt="Ludwig Multi Experiments" /></p>

                </div>
            </div>

        </div>
        

    </div>

	
    <div class="content-section-b">
    
   
        <div class="container">

            <div class="row">
                <div>
                    
                    <h2 class="section-heading">Labeling</h2>
                    

<style>
img {
  max-width: 100%;
  height: auto;
}
</style>

<p>This activity assigns names or descriptors to components within an image. Any supervised ML algorithm requires labeled data for training. Successfully trained on the labeled data, the ML algorithm is afterwards enabled to identify and name similar components in images which do not have labels.</p>

<p>Labeling is usually done manually. A user marks regions within images and assigns labels therewith identifying objects in the image. Labeled data is not questioned and provides the algorithm with ground truth data.</p>

<p><strong>Problem</strong></p>

<blockquote>
<p>BilderSkript delivers images from various lectures. We will need to repeat the labeling process to find appropriate features which let the ML based object identification algorithm generalize sufficiently well in order to identify objects in recordings from other lectures.</p>
</blockquote>

<h3 id="tool-support">Tool Support</h3>

<p>Labeling objects within images has a long history in the computer vision research community. For ML-based products there are a couple of online services available which support labeling activties distributed across a crowd workers, integrate semi-automated quality checks and other functions when it come to large-scale applications.</p>

<p>Quora list not-complete list of labeling tools and services; some are comercial, some are open-source. Check out <a href="https://www.quora.com/What-is-the-best-image-labeling-tool-for-object-detection">https://www.quora.com/What-is-the-best-image-labeling-tool-for-object-detection</a>.</p>

<p>For BilderSkript we found the following open tools tools attractive and discuss them briefly.</p>

<ul>
<li><a href="https://github.com/NaturalIntelligence/imglab">ImgLab</a>: web based tool; Online service for immediate use available under <a href="https://imglab.in">https://imglab.in</a></li>
<li><a href="https://github.com/tzutalin/labelImg">LabelImg</a>: the classic one, often mentioned on towardsdatascience.com. Google finds <a href="https://www.google.com/search?client=firefox-b-d&amp;ei=bDQSXqO0GYPVkwXNm6W4CA&amp;q=%22labelimg%22+site%3Atowardsdatascience.com&amp;oq=%22labelimg%22+site%3Atowardsdatascience.com&amp;gs_l=psy-ab.3...24037.25167..25364...0.2..0.96.176.2......0....1..gws-wiz.......0i71.uuzGcOFEKy4&amp;ved=0ahUKEwijmq3DlO3mAhWD6qQKHc1NCYcQ4dUDCAo&amp;uact=5">approx. 45 hits</a>. It is a desktop tool.</li>
<li><a href="https://alpslabel.wordpress.com/">Alp&rsquo;s Labeling Tool (ALT)</a>: more than just a labeling tool; it&rsquo;s a desktop tool for Windows as well as Linux / Ubuntu.</li>
<li><a href="https://github.com/opencv/cvat">Computer Vision Annotation Tool (CVAT)</a>: web based online tool. Works with videos, too. Apart from the web GUI, there is also a REST API to programmatically access the tool.</li>
</ul>

<h3 id="imglab-to-annotate-labels">ImgLab to annotate Labels</h3>

<p>BilderSkript utilizes the <a href="https://github.com/NaturalIntelligence/imglab">ImgLab</a> for label annotations. The web based tool exports label annotation in multiple formats</p>

<ul>
<li>dlib XML</li>
<li>dlib pts</li>
<li>Pascal VOC: <a href="http://host.robots.ox.ac.uk/pascal/VOC/">standardized</a>, however, the annotation data export only works for the current image. One needs to proceed to next image to export the next image&rsquo;s annotation.</li>
<li>COCO: <a href="http://cocodataset.org/#format-data">standardized</a>, however, the exportet annotation text seems to be incomplete</li>
</ul>

<p>The dlib XML format originates from the <a href="http://dlib.net/">dlib toolkit</a> containing various machine learning algorithms. Here is an <a href="https://handmap.github.io/dlib-classifier-for-object-detection/">example using the python API</a> for using dlib tools.</p>

<p>The XML format is reduced to the very basic tags required. An example is shown below.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-XML" data-lang="XML"><span style="color:#75715e">&lt;?xml version=&#39;1.0&#39; encoding=&#39;ISO-8859-1&#39;?&gt;</span>
<span style="color:#75715e">&lt;?xml-stylesheet type=&#39;text/xsl&#39; href=&#39;image_metadata_stylesheet.xsl&#39;?&gt;</span>
<span style="color:#f92672">&lt;dataset</span><span style="color:#f92672">&gt;</span>
<span style="color:#f92672">&lt;name</span><span style="color:#f92672">&gt;</span>dlib face detection dataset generated by ImgLab<span style="color:#f92672">&lt;/name&gt;</span>
<span style="color:#f92672">&lt;comment</span><span style="color:#f92672">&gt;</span>
    This dataset is manually crafted or adjusted using ImgLab web tool
    Check more detail on https://github.com/NaturalIntelligence/imglab
<span style="color:#f92672">&lt;/comment&gt;</span>
<span style="color:#f92672">&lt;images</span><span style="color:#f92672">&gt;</span>	<span style="color:#f92672">&lt;image</span> <span style="color:#a6e22e">file=</span><span style="color:#e6db74">&#39;IMG_20191219_094800_001_flat_pc_resize_mirror.png&#39;</span><span style="color:#f92672">&gt;</span>
		<span style="color:#f92672">&lt;box</span> <span style="color:#a6e22e">top=</span><span style="color:#e6db74">&#39;36&#39;</span> <span style="color:#a6e22e">left=</span><span style="color:#e6db74">&#39;119&#39;</span> <span style="color:#a6e22e">width=</span><span style="color:#e6db74">&#39;278&#39;</span> <span style="color:#a6e22e">height=</span><span style="color:#e6db74">&#39;208&#39;</span><span style="color:#f92672">&gt;</span>
			<span style="color:#f92672">&lt;label</span><span style="color:#f92672">&gt;</span>slide<span style="color:#f92672">&lt;/label&gt;</span>
		<span style="color:#f92672">&lt;/box&gt;</span>
		<span style="color:#f92672">&lt;box</span> <span style="color:#a6e22e">top=</span><span style="color:#e6db74">&#39;31&#39;</span> <span style="color:#a6e22e">left=</span><span style="color:#e6db74">&#39;-2&#39;</span> <span style="color:#a6e22e">width=</span><span style="color:#e6db74">&#39;206&#39;</span> <span style="color:#a6e22e">height=</span><span style="color:#e6db74">&#39;319&#39;</span><span style="color:#f92672">&gt;</span>
			<span style="color:#f92672">&lt;label</span><span style="color:#f92672">&gt;</span>person<span style="color:#f92672">&lt;/label&gt;</span>
		<span style="color:#f92672">&lt;/box&gt;</span>
	<span style="color:#f92672">&lt;/image&gt;</span>
	<span style="color:#f92672">&lt;image</span> <span style="color:#a6e22e">file=</span><span style="color:#e6db74">&#39;IMG_20191219_094802_002_flat_pc_resize_mirror.png&#39;</span><span style="color:#f92672">&gt;</span>
		<span style="color:#f92672">&lt;box</span> <span style="color:#a6e22e">top=</span><span style="color:#e6db74">&#39;44&#39;</span> <span style="color:#a6e22e">left=</span><span style="color:#e6db74">&#39;1&#39;</span> <span style="color:#a6e22e">width=</span><span style="color:#e6db74">&#39;204&#39;</span> <span style="color:#a6e22e">height=</span><span style="color:#e6db74">&#39;304&#39;</span><span style="color:#f92672">&gt;</span>
			<span style="color:#f92672">&lt;label</span><span style="color:#f92672">&gt;</span>person<span style="color:#f92672">&lt;/label&gt;</span>
		<span style="color:#f92672">&lt;/box&gt;</span>
	<span style="color:#f92672">&lt;/image&gt;</span>
<span style="color:#f92672">&lt;/images&gt;</span><span style="color:#f92672">&lt;/dataset&gt;</span></code></pre></div>
<h3 id="bilderskript-labels">BilderSkript Labels</h3>

<p>We create rectangular shapes and define the following labels to annotate the shapes:</p>

<ul>
<li><tbd></li>
<li><tbd></li>
</ul>

                </div>
            </div>

        </div>
        

    </div>

	 
    <div class="content-section-a">
    
   
        <div class="container">

            <div class="row">
                <div>
                    
                    <h2 class="section-heading">Development IDE - VS code</h2>
                    

<style>
img {
  max-width: 100%;
  height: auto;
}
</style>

<p>We use VS code as the BilderSkript&rsquo;s development IDE. A docker image encapsulates the IDE and makes it accessible through the web browser. An developer&rsquo;s software and programming effort focuses mostly on writing and editing shell scripts. As a consequence, the docker image provides appropriate extensions to support this actitity.</p>

<h3 id="web-based-vs-code">Web-based VS code</h3>

<p>Start VS code</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">docker-compose up -d vscode</code></pre></div>
<p>and point the web browser to <a href="http://localhost:8080">http://localhost:8080</a>.</p>

<p>The vscode container starts with the BilderSkript repo mounted and opened. It stores its state, e.g. last file open, extensions, other settings, in the <code>vscode</code> directory within the BilderSkript&rsquo;s project dir.</p>

<h3 id="extensions">Extensions</h3>

<p>BilderSkript&rsquo;s vscode docker image and repo comes pre-installed with following extentions especially for working with shell scripts.</p>

<ul>
<li><a href="https://github.com/mvdan/sh">shfmt</a></li>
<li><a href="https://github.com/koalaman/shellcheck">shellchecker</a></li>
</ul>

<p>The shellchecker runs on-the-fly and provides quick fixes for better coding quality of shell scripts. The shfmt tool reformats the shell script. Use <code>shift + alt + f</code> to reformat the script.</p>

<h3 id="git">Git</h3>

<p>Git version control within the vscode image misses <code>user.name</code> and <code>user.email</code> for git actions like commit. There is an extensive discussion on <a href="https://stackoverflow.com/questions/42318673/changing-the-git-user-inside-visual-studio-code">https://stackoverflow.com/questions/42318673/changing-the-git-user-inside-visual-studio-code</a>. The main message is</p>

<blockquote>
<p>Changing the git user inside Visual Studio Code, is not inside rather outside.</p>
</blockquote>

<p>This would require a developer to run <code>git config --global user....</code> commands on within vscode&rsquo;s CLI.</p>

<p>BilderSkript&rsquo;s <code>docker-compose.yml</code> file maps a .gitconfig file from the project dir onto the vscode&rsquo;s container <code>$HOME/.gitconfig</code>. As a result, it makes git configuration data available to the vscode container.</p>

<p>By default, the <code>.gitconfig</code> is included in the project&rsquo;s <code>.gitignore</code> file to avoid accidentially committing private git configuration details into the public repo.</p>

                </div>
            </div>

        </div>
        

    </div>

	
    <div class="content-section-b">
    
   
        <div class="container">

            <div class="row">
                <div>
                    
                    <h2 class="section-heading">Versioning and Repository Management</h2>
                    

<h3 id="pipeline-code-and-data-versioning">Pipeline Code and Data Versioning</h3>

<p>The <code>builder</code> image takes care of versioning using [git]() and [dvc]().</p>

<p>Pipelines are commonly shared in various volumes.</p>

<h3 id="repository-management">Repository Management</h3>

<p>The <a href="https://github.com/cdeck3r/BilderSkript">project&rsquo;s repository</a> is mounted as separate volume in the <code>builder</code> container. As a consequence, only makefiles in the project&rsquo;s root dir are able to commit changes to the repository. Scripts in subdirectories are not aware that the project&rsquo;s root is under git version control. The volumes are organized under the following two mount points.</p>

<p><strong>Mount point: <code>/BilderSkriptRepo</code></strong></p>

<p>Scripts which perform pipeline and data versioning start under this mount point. It contains all files and  directories from the project repository:</p>

<ul>
<li><code>.git/</code></li>
<li><code>Dockerfiles/</code></li>
<li>&hellip;</li>
<li><code>docker_compose.yml</code></li>
<li><code>README.md</code></li>
</ul>

<p><strong>Mount point: <code>/bilderskript</code></strong></p>

<p>Scripts which actually execute pipelines start under this mount point. It contains the following directories:</p>

<ul>
<li><code>docs/</code></li>
<li><code>docs_site/</code></li>
<li><code>images/</code></li>
<li><code>scripts/</code></li>
<li><code>src/</code></li>
</ul>

                </div>
            </div>

        </div>
        

    </div>

	 
    <div class="content-section-a">
    
   
        <div class="container">

            <div class="row">
                <div>
                    
                    <h2 class="section-heading">Documentation Generation</h2>
                    

<h3 id="docu-blog">Docu Blog</h3>

<p>The project&rsquo;s documentation is a form of a single-page blog using the <a href="https://gohugo.io/">Hugo</a> static webpage generator. It lists notes taken during the development and justifies design decisions. The <code>builder</code> docker image takes care of the generation utilizing the <code>snakemake</code> script, <a href="https://github.com/cdeck3r/BilderSkript/blob/master/pipelines/doc.snakemake"><code>pipelines/doc.snakemake</code></a>.</p>

<p>The blog utilizes the <a href="https://github.com/cdeck3r/OneDly-Theme">OneDly theme</a>. This theme is excluded from git versioning because it originates from a separate repository. One include it as a <a href="https://git-scm.com/docs/git-submodule">git submodule</a>.</p>
<pre><code>cd docs_site
git add submodule https://github.com/cdeck3r/OneDly-Theme.git themes/onedly</code></pre>
<p>The pipeline <code>doc.snakemake</code> generates the complete documentation calling</p>
<pre><code>cd /bilderskript/pipelines
snakemake -s doc.snakemake</code></pre>
<p>The docu blog is available under <a href="http://cdeck3r.com/BilderSkript/">http://cdeck3r.com/BilderSkript/</a>.</p>

                </div>
            </div>

        </div>
        

    </div>

	
    <div class="content-section-b">
    
   
        <div class="container">

            <div class="row">
                <div>
                    
                    <h2 class="section-heading">APPENDIX: Pipeline Interprocess Communication (IPC)</h2>
                    

<style>
img {
  max-width: 100%;
  height: auto;
}
</style>

<p>The distribution of pipelines across various docker containers requires interprocess communication between the docker containers. Let&rsquo;s discuss the design for the BilderSkript pipelines.</p>

<h3 id="ipc-control-problem">IPC Control Problem</h3>

<p>We have the <code>builder</code> container which controls the execution of all pipelines. A pipeline implements a  sequence of processs executions, where some of the processes run in their respective containers. As an example consider the data preparation pipeline. The pipeline in the <code>builder</code> container initiates the image data preparation in the <code>hugin</code> container. Once the process in the <code>hugin</code> container completes the pipeline can continues with the next step.</p>

<p><img src="uml/ipc_call.png" alt="ipc sequence diagram" /></p>

<p>Basically, the sequence diagram above depicts a synchronous remote procedure call (RPC). This is a classical function in many programming languages, e.g. <a href="https://en.wikipedia.org/wiki/Java_remote_method_invocation">Java RMI</a>.</p>

<p><strong>IPC control problem formulation:</strong></p>

<blockquote>
<p>Implement a synchronous RPC to start processes across containers and that seamlessly integrates into pipelined workflows.</p>
</blockquote>

<p>Contraints / requirements:</p>

<ul>
<li>low effort for additional network setup</li>
<li>low effort for access and securing the access control</li>
<li>script based, preferrably in bash, as it makes it easy to integrate the RPC as shell command.</li>
</ul>

<p>In the following sections, we discuss some IPC approaches for their qualification as synchronous RPC.</p>

<h3 id="file-based-ipc">File-based IPC</h3>

<p>A very simple, but effective approach is the use of files for exchanging messages between container processes. The process in container A writes a message character string into a file on a shared volume from which the process in container B can read the file&rsquo;s content. In this scenario, a single file serves as a buffer between those processes. However, the file access needs to be coordinated, otherwise the processes would overwrite each other&rsquo;s messages. Additionally, to get informed about new messages, the processes need to poll the commonly shared file.</p>

<h3 id="client-server-ipc">Client / Server IPC</h3>

<p>Process within different containers may communicate as networked client and servers. Subsequently, some options:</p>

<ul>
<li>REST or similar RPC-alike calls across the network</li>
<li>SSH remote script execution</li>
<li>Shared UNIX sockets</li>
</ul>

<p>REST requests are easy to implement, addtionally, a webserver such as nginx or apache is required to receive the requests. Alternatively, one could implement a simple webserver using python and flask. SSH remote script execution needs accounts to login to the remote containers. One needs to enter a password before execution, which limits automation capabilities. Public key access can resolve this problem, but needs caution in handling public and private keys. Both options expose containers to the network. As a consequence, it requires network definition between containers and a firewall to block unauthorized access.</p>

<p>Finally, UNIX sockets appear to be an ideal approach to interprocess communication. Sockets are stored on a  shared volume, therewith enabling a local access control. However, this type of interprocess communication is limited between containers on the same host.</p>

<h3 id="message-queues-and-brokers">Message Queues and Brokers</h3>

<p>A message broker maintains a message queue (MQ), where distirbuted processes can register themselve to exchange messages without directly knowing each other.</p>

<p>Message brokers are a prefered way for decoupled distributed processes, in particular for long running processes executed asynchronously. However, the setup and managment of a MQ takes effort. Processes need to agree on the message format and containers need to reach the broker&rsquo;s queue via the network.</p>

<h3 id="databases-for-ipc">Databases for IPC</h3>

<p>Databases store information, which are accessible by clients. As such, this is related to the file-based IPC. Process information is organized in tables and table attributes store process states, e.g. process execution start or whether a process successfully completed.</p>

<p>Similar to file-based IPC, processes are required to poll the database to receive updates on the process state. Addtionally, the setup and maintenance of even simple DBMS is significant. A simple file based database, e.g. <a href="https://www.sqlite.org/index.html">sqlite</a>, is an attractive solution for this last issue. However, write and read access must be coordinated to avoid (orphaned) file locks.</p>

<h3 id="final-design-decision">Final Design Decision</h3>

<p>As a result of the discussion, BilderSkript implements an interprocess communication using shared UNIX sockets. It combines the charm of file based approaches with the advantage of bi-directional communication. Tool support for scripting is very mature. The next section provides more details how this approach implemented.</p>

<p><strong>Limitation.</strong> The use of UNIX limits IPC between containers on the same host. To overcome one may use <code>socat</code> to forward the UNIX socket to a TCP one. See this <a href="https://stackoverflow.com/questions/24956322/can-docker-port-forward-to-a-unix-file-socket-on-the-host-container">stackoverflow post</a> to get an idea how this can be implemented. However, this would re-open the discussion on network access issues, but enables a migration path to evolve the local host approach to distributed network approach.</p>

<p><strong>Further Ressources:</strong></p>

<p>There are a couple of ressources to follow up on these issues.</p>

<ul>
<li><a href="https://www.linode.com/docs/security/authentication/use-public-key-authentication-with-ssh/">https://www.linode.com/docs/security/authentication/use-public-key-authentication-with-ssh/</a></li>
<li><a href="https://docs.docker.com/engine/examples/running_ssh_service/">Dockerize an SSH service</a> and <a href="https://hub.docker.com/r/rastasheep/ubuntu-sshd/">ubuntu sshd</a></li>
<li><a href="https://stackoverflow.com/questions/12202587/automatically-enter-ssh-password-with-script">sshpass</a> and <a href="https://docs.docker.com/engine/swarm/#build-support-for-docker-secrets-into-your-images">Docker secret</a></li>
<li><a href="https://jpetazzo.github.io/2014/06/23/docker-ssh-considered-evil/">Docker ssh considered evil</a></li>
</ul>

<p>An interesting op-ed from Bozho&rsquo;s tech blog is <a href="https://techblog.bozho.net/you-probably-dont-need-a-message-queue/">You Probably Don’t Need a Message Queue</a>. It inspired some of the disussion above.</p>

                </div>
            </div>

        </div>
        

    </div>

	 
    <div class="content-section-a">
    
   
        <div class="container">

            <div class="row">
                <div>
                    
                    <h2 class="section-heading">APPENDIX: IPC via Shared UNIX Sockets</h2>
                    

<style>
img {
  max-width: 100%;
  height: auto;
}
</style>

<p>This is a technical design description on the usage of shared UNIX socket for docker container IPC. Both containers connect to a socket stored on a shared volume, e.g. under the mount point <code>ipc</code>. They exchange simple control messages to run scripts and read and write data from the shared volume.</p>

<p><img src="uml/ipc_socket_docker.png" alt="ipc socket between docker containers" /></p>

<p>The approach utilizes</p>

<ul>
<li><a href="https://linux.die.net/man/1/socat"><code>socat</code></a> for creating sockets and socket communication</li>
<li><a href="https://linux.die.net/man/8/ss"><code>ss</code></a> to check for the presence of the listening socket.</li>
</ul>

<p>It follows a classical client / server approach where the server initializes the socket and waits for the client to start the communication. The following sequence diagrams depicts the interaction over the socket.</p>

<p><img src="uml/ipc_socket.png" alt="ipc socket sequence diagram" /></p>

<p>Here are the script calls for the server and client.</p>

<p><strong><a href="https://github.com/cdeck3r/BilderSkript/blob/master/scripts/ipc_socket_server.sh">Server</a>:</strong></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">./ipc_socket_server.sh &lt;socket name&gt; &lt;path/to/server_app.sh&gt;</code></pre></div>
<p><strong><a href="https://github.com/cdeck3r/BilderSkript/blob/master/scripts/ipc_socket_client.sh">Client</a>:</strong></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">./ipc_socket_client.sh &lt;socket name&gt; &lt;path/to/client_app.sh&gt;</code></pre></div>
<h3 id="cross-container-ipc-example">Cross Container IPC Example</h3>

<p>We illustrate the container IPC between the <code>builder</code> container and the <code>hugin</code> container. The <code>hugin</code> container processes all images taken with the 360 camera and converts the fisheye lens images in regular ones using a equirectangular projection. The server script runs on the <code>hugin</code> container while the client script runs on the <code>builder</code> container. The socket between both resides on a shared volume.
It starts by the snakemake file on the <code>builder</code> calling the <code>hugin.sh</code> script.</p>

<p><img src="uml/ipc_socket_hugin.png" alt="ipc socket communication between builder and hugin" /></p>

<p><strong>Ressources:</strong></p>

<p>A brief tutorial on <code>socat</code> is the <a href="https://blog.travismclarke.com/post/socat-tutorial/">Socat Cheatsheet</a> from Travis Clarke.</p>

                </div>
            </div>

        </div>
        

    </div>


</section>


<footer>
    <div class="container">
        <div class="row">
            <div class="col-md-8" style="padding-left: 0px; width:100%">
				<ul class="list-inline">
					<li>
						<a class="page-scroll" href="#intro">Up</a>
					</li>
					<li class="footer-menu-divider">&sdot;</li>
						<li>
							<a href="https://cdeck3r.com/BilderSkript/imprint-gdpr/imprint" >Imprint</a>
						</li>
					<li class="footer-menu-divider">&sdot;</li>
						<li>
							<a href="https://cdeck3r.com/BilderSkript/imprint-gdpr/gdpr" >GDPR</a>
						</li>
				 </ul>
				 <p class="copyright text-muted small" style="text-align:left;">
                    Copyright &copy; BilderSkript All Rights Reserved 
                        </br>Built with <a href="http://gohugo.io">Hugo</a> and the <a href="https://github.com/cdeck3r/OneDly-Theme">OneDly project</a> theme.
                 </p>
			</div>
            
        </div>
    </div>
</footer>

<script src="js/jquery-1.11.0.js"></script>


<script src="js/jquery.easing.min.js"></script>


<script src="js/bootstrap.min.js"></script>



</body>
</html>

