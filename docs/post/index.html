<!DOCTYPE html>
<html>
<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
	<meta name="description" content="
		
		Project&#39;s Engineering Documentation
		"> 
    
	<meta name="author" content=" cdeck3r ">  
    <base href="http://cdeck3r.com/BilderSkript/">
    <title>Sections</title>

    
    <link href="css/bootstrap.min.css" rel="stylesheet">

    
    <link href="css/landing-page.css" rel="stylesheet">

    
    <link href="https://fonts.googleapis.com/css?family=Lato:300,400,700,300italic,400italic,700italic" rel="stylesheet" type="text/css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">

    
    <link href="css/bootstrap-social.css" rel="stylesheet">

    
    
    

    <style>
    .navbar {
    border-color: #e7e7e7;
}

.content-section-a,
footer,
.navbar {
  background-color: #f8f8f8;
  color: #333;
}

.navbar a:link,
.navbar-default .navbar-nav>li>a {
  color: #777;
}

.navbar a:hover,
.navbar-default .navbar-nav>li>a:hover {
  color: rgb(51, 51, 51);
}

.content-section-b {
  background-color: white;
  color: #333;
}

body {
  color: rgb(51, 51, 51);
}

.header-container h1,
.header-container h2,
.header-container h3,
.header-container h4 {
  color: rgb(51, 51, 51);
}

  </style>

</head>
<body>

<section id="intro">
	
	<div class="intro-header">

		<div class="container">
			<div class="row">
				<div class="col-lg-12">
				
					<div class="intro-message">
						<h1>BilderSkript</h1>
						<h3>Project&#39;s Engineering Documentation</h3>
						<hr class="intro-divider">

						<ul class="list-inline intro-social-buttons">
						


  <li><a href="//github.com/cdeck3r/BilderSkript" class="btn btn-default btn-lg" title="GitHub">
  <i class="fa fa-github"></i>
  </a></li>


























  <li><a href="//linkedin.com/in/cdeck3r" title="LinkedIn" class="btn btn-default btn-lg">
  <i class="fa fa-linkedin"></i>
  </a></li>



















  <li><a href="//youtube.com/channel/UCZ5wNVV_E6AA3L3C-mvqwSA" title="YouTube" class="btn btn-default btn-lg">
  <i class="fa fa-youtube"></i>
  </a></li>













  <li><a href="//instagram.com/cdeck3r" title="Instagram" class="btn btn-default btn-lg">
  <i class="fa fa-instagram"></i>
  </a></li>





  <li><a href="//twitter.com/cdeck3r" title="Twitter" class="btn btn-default btn-lg">
  <i class="fa fa-twitter"></i>
  </a></li>



















  <li><a href="mailto:info@cdeck3r.com" title="Email" class="btn btn-default btn-lg">
  <i class="fa fa-envelope"></i>
  </a></li>


						</ul>
					</div>
				</div>
			</div>
		</div>
		
	</div>
	
</section>

<section id="main">



	 
    <div class="content-section-a">
    
   
        <div class="container">

            <div class="row">
                <div>
                    <hr class="section-heading-spacer">
                    <div class="clearfix"></div>
                    <h2 class="section-heading">About</h2>
                    

<h2 id="bilderskript">BilderSkript</h2>

<p>BilderSkript is a compound created from the following words.</p>

<blockquote>
<p>Bilder [ˈbɪldɐ], (German), images</p>

<p>Skript [skʁɪpt], (German), a written document or notes</p>
</blockquote>

<p>BilderSkript automatically summarizes a lecture as a sequence of interesting images scenes.</p>

<p>Technically, it trains a deep neural net on objection recognition and extracts interesting scenes from a large sequence of still image recordings. Theses scenes compile to the BilderSkript</p>

                </div>
            </div>

        </div>
        

    </div>

	
    <div class="content-section-b">
    
   
        <div class="container">

            <div class="row">
                <div>
                    <hr class="section-heading-spacer">
                    <div class="clearfix"></div>
                    <h2 class="section-heading">Project Definition</h2>
                    

<h3 id="motivation-and-goal">Motivation and Goal</h3>

<p>A lecturer usually provides a lot of supplemental course material such as a written script, slides, reading material, exercises.</p>

<p>However, students visiting the course&rsquo;s lecture experience an additional channel, which helps them to sort and weight the supplemental material. The way how a lecturer presents the content will let attendees realize the weight and importance of certain parts of the content. Hence, it supports the creation of a red thread throughout entire supplemental material.</p>

<p>In contrast to full lecture recording, the BilderSkript approach condenses the recording to find those parts within a lecture which contribute to the understanding of the supplemental material.</p>

<p>Primarily, BilderSkript aims at course attendees, however, it could also be valuable for remote attentees.</p>

<p>BilderSkript has the following goals</p>

<ul>
<li>re-create partially the course experience</li>
<li>support attenting students to follow-up on the content</li>
<li>support students who have not attended all lessions to catch-up on the course</li>
<li>improve the efficiency when working with the supplemental course material</li>
</ul>

<h3 id="objectives">Objectives</h3>

<p>There are a couple of activities to perform</p>

<ul>
<li>record lectures as a sequence of wide angle still images</li>
<li>train a computer to identify objects within still images</li>
<li>define a metric of interestingness from the sequence of recognized objects</li>
<li>extract interesting images and compile a lecture notebook from which ultimately creates the BilderSkript</li>
</ul>

<h3 id="research-questions">Research Questions</h3>

<p>BilderSkript relies on widely available open-source ML software. However, there are a couple of interesting research questions on the way.</p>

<ul>
<li><strong>How to automate image preprocessing?</strong> - Image recording activity does not happen in a controlled environment, i.e. lecture rooms changes, light varies, camera postions are not fixed (resulting in varying field of views), varying colors of background, cloths etc.</li>
<li><strong>Transfer learning?</strong> - object identfication &hellip; trained on labeled data from one lecture, apply model to different lecture &hellip; relates to transfer learning?</li>
</ul>

                </div>
            </div>

        </div>
        

    </div>

	 
    <div class="content-section-a">
    
   
        <div class="container">

            <div class="row">
                <div>
                    <hr class="section-heading-spacer">
                    <div class="clearfix"></div>
                    <h2 class="section-heading">Introductionary Example</h2>
                    <p>BilderSkript takes a series of still images as input and compiles visual lecture notes as output.
Below we illustrate a step-by-step walkthrough how the software processes the data.</p>

<p><strong>Image recording:</strong> A 360 camera records the entire room. However, the lens towards the audience is covered to maintain privacy. The images have the typical distorted appearance due to the camera&rsquo;s fisheye lenses. Nevertheless, it creates an approx. 200 degrees, wide-angle recording.</p>

<p><em>tbd. include image</em></p>

<p><strong>Image preparation:</strong> The BilderSkript projects fisheye images as equirectangular images to correct for the distortion.</p>

<p><em>tbd. include image</em></p>

<p><strong>Object identfication:</strong> In this step BilderSkript identifies typical objects, such as blackboard, lecturer, video projection, within each image.</p>

<p><em>tbd. include image</em></p>

<p><strong>Sequencing:</strong> Utilizing the object id, it transforms the set of images into a sequence of object compositions. A step consists of all identified objects in a single image. Please note, each step links back to the original image.</p>

<p><em>tbd. include image</em></p>

<p><strong>Interesting sequences:</strong> This steps only operates on the sequence of identified objects. Based on a definition on interestingness, it quantifies the previously created sequences on this metric. The idea is that interestingness emerges from changes in the composition of identified objects.</p>

<p><em>tbd. include image</em></p>

<p><strong>Compilation:</strong> By the degree of interestingness BilderSkript applies a threshold to extract the best ones. Once it has found an interesting sequence, it links each step within this sequence back to its image where it originates from. Finally, it compiles the scene from these images.</p>

<p><em>tbd. include image</em></p>

                </div>
            </div>

        </div>
        

    </div>

	
    <div class="content-section-b">
    
   
        <div class="container">

            <div class="row">
                <div>
                    <hr class="section-heading-spacer">
                    <div class="clearfix"></div>
                    <h2 class="section-heading">Docker Container Toolchain</h2>
                    

<style>
img {
  max-width: 100%;
  height: auto;
}
</style>

<h3 id="docker-images-and-volumes">Docker Images and Volumes</h3>

<p>Docker images contain the various software pipelines from the tool chain. The various responsibilities within the overall system design motivate the system boundaries induced by the distribution of pipelines across docker images. The following table list the docker images and their respective pipeline functionalities.</p>

<table>
<thead>
<tr>
<th>Image</th>
<th>Pipeline</th>
<th>Notes</th>
</tr>
</thead>

<tbody>
<tr>
<td>builder</td>
<td>Build</td>
<td>makefile, doc, versioning via git and dvc, mlflow exp.</td>
</tr>

<tr>
<td>hugin</td>
<td>Data prep</td>
<td>image data preparation</td>
</tr>

<tr>
<td>ludwig</td>
<td>ML training</td>
<td>training and experimentation</td>
</tr>

<tr>
<td>cicd</td>
<td>Deployment pipeline</td>
<td>not yet implemented</td>
</tr>
</tbody>
</table>

<p>When started as docker containers, they run scripts and communicate with each other utilizing shared volumes on the filesystem. The image below illustrates the docker toolchain.</p>

<p><img src="uml/docker_toolchain.png" alt="docker toolchain" /></p>

<p>The most important volumes are:</p>

<ul>
<li>${APP_ROOT}/ipc : used to store sockets for IPCs between containers</li>
<li>${APP_ROOT}/pipelines : contains all BilderSkript pipelines</li>
<li>${APP_ROOT}/images : data directory</li>
<li>${APP_ROOT}/src : stores source codes</li>
<li>${APP_ROOT}/scripts : scripts</li>
<li>${APP_ROOT}/docs :  docu blog directory</li>
<li>${APP_ROOT}/docs_site : the docu blog&rsquo;s source</li>
</ul>

<p>By default <code>${APP_ROOT}</code> is set to <code>/bilderskript</code>. For instance, one accesses the pipeline scripts under <code>/bilderskript/pipelines</code>.</p>

<h3 id="build-and-startup">Build and Startup</h3>

<p><a href="https://docs.docker.com/compose/">Docker Compose</a> creates all images, containers and volumes. The configuration is defined in the <a href="https://github.com/cdeck3r/BilderSkript/blob/master/docker-compose.yml">docker-compose.yml</a> file</p>

<p>Building all images using the following command</p>
<pre><code>docker-compose build</code></pre>
<p>Start a container from <code>builder</code> image  and get a <code>bash</code> shell. The default container name is <code>bilderskript_builder_1</code></p>
<pre><code>docker-compose up -d builder
docker exec -it bilderskript_builder_1 /bin/bash</code></pre>
                </div>
            </div>

        </div>
        

    </div>

	 
    <div class="content-section-a">
    
   
        <div class="container">

            <div class="row">
                <div>
                    <hr class="section-heading-spacer">
                    <div class="clearfix"></div>
                    <h2 class="section-heading">Pipelines</h2>
                    

<style>
img {
  max-width: 100%;
  height: auto;
}
</style>

<p>Pipelines are the fundamental building blocks of BilderSkript.</p>

<h3 id="pipeline-definitions">Pipeline Definitions</h3>

<p>The term pipeline is heavily used in machine learning (ML). It generally refers to a sequence of steps to run in order to perform transformations. There are various kinds of pipelines, e.g. data pipelines, machine learning pipelines, deployment pipelines and others. Depending on the pipeline type, it takes a a certain ressource type as input and produces output ressources by the application of the pipeline&rsquo;s transformation steps. For instance, a data pipeline takes data files as an input and prepares them to be fed into a machine learning algorithm of the ML pipeline.</p>

<p>BilderSkript stores pipelines in the <code>pipelines</code> volume usually accessed under <code>/bilderscript/pipelines</code>. They are encoded as snakemake makefiles for version control.</p>

<h3 id="snakemake">Snakemake</h3>

<p><a href="https://snakemake.readthedocs.io/en/stable/">Snakemake</a> is a workflow management system to implement data analysis pipelines.</p>

<p>Snakemake compares the input and output ressources. These ressources are files. If the modification date of any of the input files is newer than the output file, snakemake runs the shell command. This behavior is encoded as rules, which transform input files into output files. All rules of a pipeline are defined in a snakefile. We list some important snakemake commands.</p>

<p>Run the snakemake pipeline</p>
<pre><code>snakemake -s <snakefile></code></pre>
<p>Generate a report</p>
<pre><code>snakemake -s <snakefile> --report <snakefile.html></code></pre>
<p>Generate a summary table displaying the current state of input and output files.</p>
<pre><code>snakemake -s <snakefile> --summary</code></pre>
<p>Before the snakefile is run, snakemake generates a <a href="https://en.wikipedia.org/wiki/Directed_acyclic_graph">DAG</a> which shows the dependencies. This command visualizes the DAG.</p>
<pre><code>snakemake -s <snakefile> --dag | dot -Tpng > snakefile.png</code></pre>
<h3 id="important-bilderskript-pipelines">Important BilderSkript Pipelines</h3>

<p>The pipelines are named after their snakefile.</p>

<p><strong><a href="https://github.com/cdeck3r/BilderSkript/blob/master/pipelines/doc.snakefile">doc.snakefile</a>:</strong> describes the pipeline for documentation generations. You may see the pipeline&rsquo;s <a href="https://github.com/cdeck3r/BilderSkript/blob/master/pipelines/doc.snakefile.html">report</a>.</p>

<p><strong><a href="https://github.com/cdeck3r/BilderSkript/blob/master/pipelines/data_prep.snakefile">data_prep.snakefile</a>:</strong> prepares the image files for the ML pipeline. It&rsquo;s a complex pipeline because it utilizes interprocess communication (IPC) with <code>hugin</code> container. <code>data_prep.snakefile</code> requires the following parameters:</p>

<ul>
<li>imgdir: the directory where the camera images are located</li>
<li>outdir: the directory where prep&rsquo;ed images as a result of the pipeline execution are stored</li>
</ul>

<p>The pipeline&rsquo;s default behavior is started by the <a href="https://github.com/cdeck3r/BilderSkript/blob/master/pipelines/data_prep.sh"><code>data_prep.sh</code></a> script.</p>

                </div>
            </div>

        </div>
        

    </div>

	
    <div class="content-section-b">
    
   
        <div class="container">

            <div class="row">
                <div>
                    <hr class="section-heading-spacer">
                    <div class="clearfix"></div>
                    <h2 class="section-heading">Pipeline Interprocess Communication (IPC)</h2>
                    

<style>
img {
  max-width: 100%;
  height: auto;
}
</style>

<p>The distribution of pipelines across various docker containers requires interprocess communication between the docker containers. Let&rsquo;s discuss the design for the BilderSkript pipelines.</p>

<h3 id="ipc-control-problem">IPC Control Problem</h3>

<p>We have the <code>builder</code> container which controls the execution of all pipelines. A pipeline implements a  sequence of processs executions, where some of the processes run in their respective containers. As an example consider the data preparation pipeline. The pipeline in the <code>builder</code> container initiates the image data preparation in the <code>hugin</code> container. Once the process in the <code>hugin</code> container completes the pipeline can continues with the next step.</p>

<p><img src="uml/ipc_call.png" alt="ipc sequence diagram" /></p>

<p>Basically, the sequence diagram above depicts a synchronous remote procedure call (RPC). This is a classical function in many programming languages, e.g. <a href="https://en.wikipedia.org/wiki/Java_remote_method_invocation">Java RMI</a>.</p>

<p><strong>IPC control problem formulation:</strong></p>

<blockquote>
<p>Implement a synchronous RPC to start processes across containers and that seamlessly integrates into pipelined workflows.</p>
</blockquote>

<p>Contraints / requirements:</p>

<ul>
<li>low effort for additional network setup</li>
<li>low effort for access and securing the access control</li>
<li>script based, preferrably in bash, as it makes it easy to integrate the RPC as shell command.</li>
</ul>

<p>In the following sections, we discuss some IPC approaches for their qualification as synchronous RPC.</p>

<h3 id="file-based-ipc">File-based IPC</h3>

<p>A very simple, but effective approach is the use of files for exchanging messages between container processes. The process in container A writes a message character string into a file on a shared volume from which the process in container B can read the file&rsquo;s content. In this scenario, a single file serves as a buffer between those processes. However, the file access needs to be coordinated, otherwise the processes would overwrite each other&rsquo;s messages. Additionally, to get informed about new messages, the processes need to poll the commonly shared file.</p>

<h3 id="client-server-ipc">Client / Server IPC</h3>

<p>Process within different containers may communicate as networked client and servers. Subsequently, some options:</p>

<ul>
<li>REST or similar RPC-alike calls across the network</li>
<li>SSH remote script execution</li>
<li>Shared UNIX sockets</li>
</ul>

<p>REST requests are easy to implement, addtionally, a webserver such as nginx or apache is required to receive the requests. Alternatively, one could implement a simple webserver using python and flask. SSH remote script execution needs accounts to login to the remote containers. One needs to enter a password before execution, which limits automation capabilities. Public key access can resolve this problem, but needs caution in handling public and private keys. Both options expose containers to the network. As a consequence, it requires network definition between containers and a firewall to block unauthorized access.</p>

<p>Finally, UNIX sockets appear to be an ideal approach to interprocess communication. Sockets are stored on a  shared volume, therewith enabling a local access control. However, this type of interprocess communication is limited between containers on the same host.</p>

<h3 id="message-queues-and-brokers">Message Queues and Brokers</h3>

<p>A message broker maintains a message queue (MQ), where distirbuted processes can register themselve to exchange messages without directly knowing each other.</p>

<p>Message brokers are a prefered way for decoupled distributed processes, in particular for long running processes executed asynchronously. However, the setup and managment of a MQ takes effort. Processes need to agree on the message format and containers need to reach the broker&rsquo;s queue via the network.</p>

<h3 id="databases-for-ipc">Databases for IPC</h3>

<p>Databases store information, which are accessible by clients. As such, this is related to the file-based IPC. Process information is organized in tables and table attributes store process states, e.g. process execution start or whether a process successfully completed.</p>

<p>Similar to file-based IPC, processes are required to poll the database to receive updates on the process state. Addtionally, the setup and maintenance of even simple DBMS is significant. A simple file based database, e.g. <a href="https://www.sqlite.org/index.html">sqlite</a>, is an attractive solution for this last issue. However, write and read access must be coordinated to avoid (orphaned) file locks.</p>

<h3 id="final-design-decision">Final Design Decision</h3>

<p>As a result of the discussion, BilderSkript implements an interprocess communication using shared UNIX sockets. It combines the charm of file based approaches with the advantage of bi-directional communication. Tool support for scripting is very mature. The next section provides more details how this approach implemented.</p>

<p><strong>Limitation.</strong> The use of UNIX limits IPC between containers on the same host. To overcome one may use <code>socat</code> to forward the UNIX socket to a TCP one. See this <a href="https://stackoverflow.com/questions/24956322/can-docker-port-forward-to-a-unix-file-socket-on-the-host-container">stackoverflow post</a> to get an idea how this can be implemented. However, this would re-open the discussion on network access issues, but enables a migration path to evolve the local host approach to distributed network approach.</p>

<p><strong>Further Ressources:</strong></p>

<p>There are a couple of ressources to follow up on these issues.</p>

<ul>
<li><a href="https://www.linode.com/docs/security/authentication/use-public-key-authentication-with-ssh/">https://www.linode.com/docs/security/authentication/use-public-key-authentication-with-ssh/</a></li>
<li><a href="https://docs.docker.com/engine/examples/running_ssh_service/">Dockerize an SSH service</a> and <a href="https://hub.docker.com/r/rastasheep/ubuntu-sshd/">ubuntu sshd</a></li>
<li><a href="https://stackoverflow.com/questions/12202587/automatically-enter-ssh-password-with-script">sshpass</a> and <a href="https://docs.docker.com/engine/swarm/#build-support-for-docker-secrets-into-your-images">Docker secret</a></li>
<li><a href="https://jpetazzo.github.io/2014/06/23/docker-ssh-considered-evil/">Docker ssh considered evil</a></li>
</ul>

<p>An interesting op-ed from Bozho&rsquo;s tech blog is <a href="https://techblog.bozho.net/you-probably-dont-need-a-message-queue/">You Probably Don’t Need a Message Queue</a>. It inspired some of the disussion above.</p>

                </div>
            </div>

        </div>
        

    </div>

	 
    <div class="content-section-a">
    
   
        <div class="container">

            <div class="row">
                <div>
                    <hr class="section-heading-spacer">
                    <div class="clearfix"></div>
                    <h2 class="section-heading">IPC via Shared UNIX Sockets</h2>
                    

<style>
img {
  max-width: 100%;
  height: auto;
}
</style>

<p>This is a technical design description on the usage of shared UNIX socket for docker container IPC.</p>

<p>The approach utilizes</p>

<ul>
<li><a href="https://linux.die.net/man/1/socat"><code>socat</code></a> for creating sockets and socket communication</li>
<li><a href="https://linux.die.net/man/8/ss"><code>ss</code></a> to check for the presence of the listening socket.</li>
</ul>

<p>It follows a classical client / server approach where the server initializes the socket and waits for the client to start the communication. The following sequence diagrams depicts the interaction over the socket.</p>

<p><img src="uml/ipc_socket.png" alt="ipc socket sequence diagram" /></p>

<p>Here are the script calls for the server and client.</p>

<p><strong><a href="https://github.com/cdeck3r/BilderSkript/blob/master/scripts/ipc_socket_server.sh">Server</a>:</strong></p>
<pre><code>./ipc_socket_server.sh <socket name> <path/to/server_app.sh></code></pre>
<p><strong><a href="https://github.com/cdeck3r/BilderSkript/blob/master/scripts/ipc_socket_client.sh">Client</a>:</strong></p>
<pre><code>./ipc_socket_client.sh <socket name> <path/to/client_app.sh></code></pre>
<h3 id="cross-container-ipc-example">Cross Container IPC Example</h3>

<p>We illustrate the container IPC between the <code>builder</code> container and the <code>hugin</code> container. The <code>hugin</code> container processes all images taken with the 360 camera and converts the fisheye lens images in regular ones using a equirectangular projection. The server script runs on the <code>hugin</code> container while the client script runs on the <code>builder</code> container. The socket between both resides on a shared volume.
It starts by the snakemake file on the <code>builder</code> calling the <code>hugin.sh</code> script.</p>

<p><img src="uml/ipc_socket.png" alt="ipc socket communication between builder and hugin" /></p>

<p><strong>Ressources:</strong></p>

<p>A brief tutorial on <code>socat</code> is the <a href="https://blog.travismclarke.com/post/socat-tutorial/">Socat Cheatsheet</a> from Travis Clarke.</p>

                </div>
            </div>

        </div>
        

    </div>

	
    <div class="content-section-b">
    
   
        <div class="container">

            <div class="row">
                <div>
                    <hr class="section-heading-spacer">
                    <div class="clearfix"></div>
                    <h2 class="section-heading">Labeling</h2>
                    

<style>
img {
  max-width: 100%;
  height: auto;
}
</style>

<p>This activity assigns names or descriptors to components within an image. Any supervised ML algorithm requires labeled data for training. Successfully trained on the labeled data, the ML algorithm is afterwards enabled to identify and name similar components in images which do not have labels.</p>

<p>Labeling is usually done manually. A user marks regions within images and assigns labels therewith identifying objects in the image. Labeled data is not questioned and provides the algorithm with ground truth data.</p>

<p><strong>Problem</strong></p>

<blockquote>
<p>BilderSkript delivers images from various lectures. We will need to repeat the labeling process to find appropriate features which let the ML based object identification algorithm generalize sufficiently well in order to identify objects in recordings from other lectures.</p>
</blockquote>

<h3 id="tool-support">Tool Support</h3>

<p>Labeling objects within images has a long history in the computer vision research community. For ML-based products there are a couple of online services available which support labeling activties distributed across a crowd workers, integrate semi-automated quality checks and other functions when it come to large-scale applications.</p>

<p>Quora list not-complete list of labeling tools and services; some are comercial, some are open-source. Check out <a href="https://www.quora.com/What-is-the-best-image-labeling-tool-for-object-detection">https://www.quora.com/What-is-the-best-image-labeling-tool-for-object-detection</a>.</p>

<p>For BilderSkript we found the following open tools tools attractive and discuss them briefly.</p>

<ul>
<li><a href="https://github.com/NaturalIntelligence/imglab">ImgLab</a>: web based tool; Online service for immediate use available under <a href="https://imglab.in">https://imglab.in</a></li>
<li><a href="https://github.com/tzutalin/labelImg">LabelImg</a>: the classic one, often mentioned on towardsdatascience.com. Google finds <a href="https://www.google.com/search?client=firefox-b-d&amp;ei=bDQSXqO0GYPVkwXNm6W4CA&amp;q=%22labelimg%22+site%3Atowardsdatascience.com&amp;oq=%22labelimg%22+site%3Atowardsdatascience.com&amp;gs_l=psy-ab.3...24037.25167..25364...0.2..0.96.176.2......0....1..gws-wiz.......0i71.uuzGcOFEKy4&amp;ved=0ahUKEwijmq3DlO3mAhWD6qQKHc1NCYcQ4dUDCAo&amp;uact=5">approx. 45 hits</a>. It is a desktop tool.</li>
<li><a href="https://alpslabel.wordpress.com/">Alp&rsquo;s Labeling Tool (ALT)</a>: more than just a labeling tool; it&rsquo;s a desktop tool for Windows as well as Linux / Ubuntu.</li>
<li><a href="https://github.com/opencv/cvat">Computer Vision Annotation Tool (CVAT)</a>: web based online tool. Works with videos, too. Apart from the web GUI, there is also a REST API to programmatically access the tool.</li>
</ul>

<h3 id="imglab-to-annotate-labels">ImgLab to annotate Labels</h3>

<p>BilderSkript utilizes the <a href="https://github.com/NaturalIntelligence/imglab">ImgLab</a> for label annotations. The web based tool exports label annotation in multiple formats</p>

<ul>
<li>dlib XML</li>
<li>dlib pts</li>
<li>Pascal VOC: <a href="http://host.robots.ox.ac.uk/pascal/VOC/">standardized</a>, however, the annotation data export only works for the current image. One needs to proceed to next image to export the next image&rsquo;s annotation.</li>
<li>COCO: <a href="http://cocodataset.org/#format-data">standardized</a>, however, the exportet annotation text seems to be incomplete</li>
</ul>

<p>The dlib XML format originates from the <a href="http://dlib.net/">dlib toolkit</a> containing various machine learning algorithms. Here is an <a href="https://handmap.github.io/dlib-classifier-for-object-detection/">example using the python API</a> for using dlib tools.</p>

<p>The XML format is reduced to the very basic tags required. An example is shown below.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-XML" data-lang="XML"><span style="color:#75715e">&lt;?xml version=&#39;1.0&#39; encoding=&#39;ISO-8859-1&#39;?&gt;</span>
<span style="color:#75715e">&lt;?xml-stylesheet type=&#39;text/xsl&#39; href=&#39;image_metadata_stylesheet.xsl&#39;?&gt;</span>
<span style="color:#f92672">&lt;dataset</span><span style="color:#f92672">&gt;</span>
<span style="color:#f92672">&lt;name</span><span style="color:#f92672">&gt;</span>dlib face detection dataset generated by ImgLab<span style="color:#f92672">&lt;/name&gt;</span>
<span style="color:#f92672">&lt;comment</span><span style="color:#f92672">&gt;</span>
    This dataset is manually crafted or adjusted using ImgLab web tool
    Check more detail on https://github.com/NaturalIntelligence/imglab
<span style="color:#f92672">&lt;/comment&gt;</span>
<span style="color:#f92672">&lt;images</span><span style="color:#f92672">&gt;</span>	<span style="color:#f92672">&lt;image</span> <span style="color:#a6e22e">file=</span><span style="color:#e6db74">&#39;IMG_20191219_094800_001_flat_pc_resize_mirror.png&#39;</span><span style="color:#f92672">&gt;</span>
		<span style="color:#f92672">&lt;box</span> <span style="color:#a6e22e">top=</span><span style="color:#e6db74">&#39;36&#39;</span> <span style="color:#a6e22e">left=</span><span style="color:#e6db74">&#39;119&#39;</span> <span style="color:#a6e22e">width=</span><span style="color:#e6db74">&#39;278&#39;</span> <span style="color:#a6e22e">height=</span><span style="color:#e6db74">&#39;208&#39;</span><span style="color:#f92672">&gt;</span>
			<span style="color:#f92672">&lt;label</span><span style="color:#f92672">&gt;</span>slide<span style="color:#f92672">&lt;/label&gt;</span>
		<span style="color:#f92672">&lt;/box&gt;</span>
		<span style="color:#f92672">&lt;box</span> <span style="color:#a6e22e">top=</span><span style="color:#e6db74">&#39;31&#39;</span> <span style="color:#a6e22e">left=</span><span style="color:#e6db74">&#39;-2&#39;</span> <span style="color:#a6e22e">width=</span><span style="color:#e6db74">&#39;206&#39;</span> <span style="color:#a6e22e">height=</span><span style="color:#e6db74">&#39;319&#39;</span><span style="color:#f92672">&gt;</span>
			<span style="color:#f92672">&lt;label</span><span style="color:#f92672">&gt;</span>person<span style="color:#f92672">&lt;/label&gt;</span>
		<span style="color:#f92672">&lt;/box&gt;</span>
	<span style="color:#f92672">&lt;/image&gt;</span>
	<span style="color:#f92672">&lt;image</span> <span style="color:#a6e22e">file=</span><span style="color:#e6db74">&#39;IMG_20191219_094802_002_flat_pc_resize_mirror.png&#39;</span><span style="color:#f92672">&gt;</span>
		<span style="color:#f92672">&lt;box</span> <span style="color:#a6e22e">top=</span><span style="color:#e6db74">&#39;44&#39;</span> <span style="color:#a6e22e">left=</span><span style="color:#e6db74">&#39;1&#39;</span> <span style="color:#a6e22e">width=</span><span style="color:#e6db74">&#39;204&#39;</span> <span style="color:#a6e22e">height=</span><span style="color:#e6db74">&#39;304&#39;</span><span style="color:#f92672">&gt;</span>
			<span style="color:#f92672">&lt;label</span><span style="color:#f92672">&gt;</span>person<span style="color:#f92672">&lt;/label&gt;</span>
		<span style="color:#f92672">&lt;/box&gt;</span>
	<span style="color:#f92672">&lt;/image&gt;</span>
<span style="color:#f92672">&lt;/images&gt;</span><span style="color:#f92672">&lt;/dataset&gt;</span></code></pre></div>
<h3 id="bilderskript-labels">BilderSkript Labels</h3>

<p>We create rectangular shapes and define the following labels to annotate the shapes:</p>

<ul>
<li><tbd></li>
<li><tbd></li>
</ul>

                </div>
            </div>

        </div>
        

    </div>

	 
    <div class="content-section-a">
    
   
        <div class="container">

            <div class="row">
                <div>
                    <hr class="section-heading-spacer">
                    <div class="clearfix"></div>
                    <h2 class="section-heading">Versioning and Repository Management</h2>
                    

<h3 id="pipeline-code-and-data-versioning">Pipeline Code and Data Versioning</h3>

<p>The <code>builder</code> image takes care of versioning using [git]() and [dvc]().</p>

<p>Pipelines are commonly shared in various volumes.</p>

<h3 id="repository-management">Repository Management</h3>

<p>The <a href="https://github.com/cdeck3r/BilderSkript">project&rsquo;s repository</a> is mounted as separate volume in the <code>builder</code> container. As a consequence, only makefiles in the project&rsquo;s root dir are able to commit changes to the repository. Scripts in subdirectories are not aware that the project&rsquo;s root is under git version control. The volumes are organized under the following two mount points.</p>

<p><strong>Mount point: <code>/BilderSkriptRepo</code></strong></p>

<p>Scripts which perform pipeline and data versioning start under this mount point. It contains all files and  directories from the project repository:</p>

<ul>
<li><code>.git/</code></li>
<li><code>Dockerfiles/</code></li>
<li>&hellip;</li>
<li><code>docker_compose.yml</code></li>
<li><code>README.md</code></li>
</ul>

<p><strong>Mount point: <code>/bilderskript</code></strong></p>

<p>Scripts which actually execute pipelines start under this mount point. It contains the following directories:</p>

<ul>
<li><code>docs/</code></li>
<li><code>docs_site/</code></li>
<li><code>images/</code></li>
<li><code>scripts/</code></li>
<li><code>src/</code></li>
</ul>

                </div>
            </div>

        </div>
        

    </div>

	
    <div class="content-section-b">
    
   
        <div class="container">

            <div class="row">
                <div>
                    <hr class="section-heading-spacer">
                    <div class="clearfix"></div>
                    <h2 class="section-heading">Documentation Generation</h2>
                    

<h3 id="docu-blog">Docu Blog</h3>

<p>The project&rsquo;s documentation is a form of a single-page blog using the <a href="https://gohugo.io/">Hugo</a> static webpage generator. It lists notes taken during the development and justifies design decisions. The <code>builder</code> docker image takes care of the generation utilizing the <code>snakemake</code> script, <a href="https://github.com/cdeck3r/BilderSkript/blob/master/pipelines/doc.snakemake"><code>pipelines/doc.snakemake</code></a>.</p>

<p>The blog utilizes the <a href="https://github.com/cdeck3r/OneDly-Theme">OneDly theme</a>. This theme is excluded from git versioning because it originates from a separate repository. One include it as a <a href="https://git-scm.com/docs/git-submodule">git submodule</a>.</p>
<pre><code>cd docs_site
git add submodule https://github.com/cdeck3r/OneDly-Theme.git themes/onedly</code></pre>
<p>The pipeline <code>doc.snakemake</code> generates the complete documentation calling</p>
<pre><code>cd /bilderskript/pipelines
snakemake -s doc.snakemake</code></pre>
<p>The docu blog is available under <a href="http://cdeck3r.com/BilderSkript/">http://cdeck3r.com/BilderSkript/</a>.</p>

                </div>
            </div>

        </div>
        

    </div>


</section>


<footer>
    <div class="container">
        <div class="row">
            <div class="col-md-8" style="padding-left: 0px">
				<ul class="list-inline">
					<li>
						<a class="page-scroll" href="#intro">Up</a>
					</li>
					<li class="footer-menu-divider">&sdot;</li>
						<li>
							<a href="http://cdeck3r.com/BilderSkript/imprint-gdpr/imprint" >Imprint</a>
						</li>
					<li class="footer-menu-divider">&sdot;</li>
						<li>
							<a href="http://cdeck3r.com/BilderSkript/imprint-gdpr/gdpr" >GDPR</a>
						</li>
				 </ul>
				 <p class="copyright text-muted small">Copyright &copy; BilderSkript All Rights Reserved</p>
			</div>
            <div class="col-md-4" style="padding-right: 0px">
				Built with <a href="http://gohugo.io">Hugo</a> and the
				<a href="https://github.com/cdeck3r/OneDly-Theme">OneDly project</a>
				theme.
            </div>
        </div>
    </div>
</footer>

<script src="/js/jquery-1.11.0.js"></script>


<script src="/js/jquery.easing.min.js"></script>


<script src="/js/bootstrap.min.js"></script>



</body>
</html>

